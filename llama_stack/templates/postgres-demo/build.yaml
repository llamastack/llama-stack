version: 2
distribution_spec:
  description: Quick start template for running Llama Stack with several popular providers
  providers:
    inference:
    - provider_id: vllm-inference
      provider_type: remote::vllm
    - provider_id: sentence-transformers
      provider_type: inline::sentence-transformers
    vector_io:
    - provider_id: chromadb
      provider_type: remote::chromadb
    safety:
    - provider_id: llama-guard
      provider_type: inline::llama-guard
    agents:
    - provider_id: meta-reference
      provider_type: inline::meta-reference
    telemetry:
    - provider_id: meta-reference
      provider_type: inline::meta-reference
    tool_runtime:
    - provider_id: brave-search
      provider_type: remote::brave-search
    - provider_id: tavily-search
      provider_type: remote::tavily-search
    - provider_id: rag-runtime
      provider_type: inline::rag-runtime
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
image_type: conda
image_name: postgres-demo
additional_pip_packages:
- asyncpg
- psycopg2-binary
- sqlalchemy[asyncio]
