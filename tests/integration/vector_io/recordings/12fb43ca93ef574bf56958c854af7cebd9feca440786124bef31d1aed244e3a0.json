{
  "test_id": "tests/integration/vector_io/test_openai_vector_stores.py::test_openai_vector_store_file_batch_list_files[client_with_models-ollama/llama3.2:3b-instruct-fp16-None-ollama/all-minilm:l6-v2-None-384]",
  "request": {
    "method": "POST",
    "url": "http://localhost:11434/api/ps",
    "headers": {},
    "body": {},
    "endpoint": "/api/ps",
    "model": ""
  },
  "response": {
    "body": {
      "__type__": "ollama._types.ProcessResponse",
      "__data__": {
        "models": [
          {
            "model": "nomic-embed-text:latest",
            "name": "nomic-embed-text:latest",
            "digest": "0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f",
            "expires_at": "2025-10-08T14:32:00.463658-07:00",
            "size": 906873856,
            "size_vram": 906873856,
            "details": {
              "parent_model": "",
              "format": "gguf",
              "family": "nomic-bert",
              "families": [
                "nomic-bert"
              ],
              "parameter_size": "137M",
              "quantization_level": "F16"
            },
            "context_length": null
          },
          {
            "model": "all-minilm:l6-v2",
            "name": "all-minilm:l6-v2",
            "digest": "1b226e2802dbb772b5fc32a58f103ca1804ef7501331012de126ab22f67475ef",
            "expires_at": "2025-10-08T14:31:53.283774-07:00",
            "size": 585846784,
            "size_vram": 585846784,
            "details": {
              "parent_model": "",
              "format": "gguf",
              "family": "bert",
              "families": [
                "bert"
              ],
              "parameter_size": "23M",
              "quantization_level": "F16"
            },
            "context_length": null
          },
          {
            "model": "llama3.2:3b-instruct-fp16",
            "name": "llama3.2:3b-instruct-fp16",
            "digest": "195a8c01d91ec3cb1e0aad4624a51f2602c51fa7d96110f8ab5a20c84081804d",
            "expires_at": "2025-10-08T14:31:52.436459-07:00",
            "size": 8581748736,
            "size_vram": 8581748736,
            "details": {
              "parent_model": "",
              "format": "gguf",
              "family": "llama",
              "families": [
                "llama"
              ],
              "parameter_size": "3.2B",
              "quantization_level": "F16"
            },
            "context_length": null
          }
        ]
      }
    },
    "is_streaming": false
  }
}
