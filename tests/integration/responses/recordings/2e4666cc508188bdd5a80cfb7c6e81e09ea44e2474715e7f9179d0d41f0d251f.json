{
  "test_id": "tests/integration/responses/test_tool_responses.py::test_response_non_streaming_file_search_empty_vector_store[openai_client-txt=ollama/llama3.2:3b-instruct-fp16:emb=sentence-transformers/nomic-ai/nomic-embed-text-v1.5:dim=768]",
  "request": {
    "method": "POST",
    "url": "http://0.0.0.0:11434/v1/v1/chat/completions",
    "headers": {},
    "body": {
      "model": "llama3.2:3b-instruct-fp16",
      "messages": [
        {
          "role": "user",
          "content": "How many experts does the Llama 4 Maverick model have?"
        },
        {
          "role": "assistant",
          "content": "",
          "tool_calls": [
            {
              "index": 0,
              "id": "call_asn3anj9",
              "type": "function",
              "function": {
                "name": "knowledge_search",
                "arguments": "{\"query\":\"Llama 4 Maverick experts\"}"
              }
            }
          ]
        },
        {
          "role": "tool",
          "tool_call_id": "call_asn3anj9",
          "content": [
            {
              "type": "text",
              "text": "knowledge_search tool found 0 chunks:\nBEGIN of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "END of knowledge_search tool results.\n"
            },
            {
              "type": "text",
              "text": "The above results were retrieved to help answer the user's query: \"Llama 4 Maverick experts\". Use them as supporting information only in answering this query. \n"
            }
          ]
        }
      ],
      "parallel_tool_calls": true,
      "stream": true,
      "stream_options": {
        "include_usage": true
      },
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "knowledge_search",
            "description": "Search for information in a database.",
            "parameters": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string",
                  "description": "The query to search for. Can be a natural language sentence or keywords."
                }
              },
              "required": [
                "query"
              ]
            }
          }
        }
      ]
    },
    "endpoint": "/v1/chat/completions",
    "model": "llama3.2:3b-instruct-fp16"
  },
  "response": {
    "body": [
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-2e4666cc5081",
          "choices": [
            {
              "delta": {
                "content": "Unfortunately, I couldn't find any specific information on the Llama 4 Maverick model having a specified number of experts. However, I can tell you that the Llama 4 is an AI model developed by Meta, and like other large language models, it's designed to provide helpful and accurate responses to user queries. If you have any further questions or need assistance with something else, feel free to ask!",
                "function_call": null,
                "refusal": null,
                "role": "assistant",
                "tool_calls": null
              },
              "finish_reason": "stop",
              "index": 0,
              "logprobs": null
            }
          ],
          "created": 0,
          "model": "llama3.2:3b-instruct-fp16",
          "object": "chat.completion.chunk",
          "service_tier": null,
          "system_fingerprint": "fp_ollama",
          "usage": null
        }
      },
      {
        "__type__": "openai.types.chat.chat_completion_chunk.ChatCompletionChunk",
        "__data__": {
          "id": "rec-2e4666cc5081",
          "choices": [],
          "created": 0,
          "model": "llama3.2:3b-instruct-fp16",
          "object": "chat.completion.chunk",
          "service_tier": null,
          "system_fingerprint": "fp_ollama",
          "usage": {
            "completion_tokens": 84,
            "prompt_tokens": 138,
            "total_tokens": 222,
            "completion_tokens_details": null,
            "prompt_tokens_details": null
          }
        }
      }
    ],
    "is_streaming": true
  },
  "id_normalization_mapping": {}
}
